{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Digitale Bildverarbeitung Documentation | GitHub Abstract This project was developed by a team of 3 students as part of the \"Digitale-Bildverarbeitung\" course at DHBW Stuttgart . The goal was to implement an image & video processing application in Python. The application should be able to process frames to detect lanes and highlight them in the original image. Credit Credit has to be given to Addison Sears-Collins who has published an easy to understand guide for the sliding window technique used in this project. Project Requirements Camera calibration of Udacity Images & Videos Image segmentation & Bird's Eye View transformation Applying thresholds to different color spaces to highlight relevant lane markings Curve / Polynomial fitting and plotting on image Video processing > 20 FPS Additional Tasks Relevent lane markings are highlighted on the challenge_video Relevant lane markings are highlighted on each KITTI image The region of interest had to be adapted to the KITTI camera perspective Edge detection is applied to KITTI to detect lanes withouth any markings Steps for increased performance Region is transormed to a smaller image, reducing its size by a factor of 4 If enough white pixels are in close proximity to the previous polynomial, the sliding window technique is not applied. Since the proximity is narrower than the sliding windows, fitting the polynomial is faster, increasing performance. Calculations, which can be reused are performed at the beginning of a video and reused for each frame. Such as transform_matrix and camera calibration . Requirements & Installation Python 3.10 is required Using Poetry Install Poetry # Linux, macOS, and Windows (WSL) curl -sSL https://install.python-poetry.org | python3 - # Windows (PowerShell) ( Invoke-WebRequest -Uri https://install.python-poetry.org -UseBasicParsing ) .Content | py - Install dependencies poetry install Running commands poetry run <command> Using pip pip install -r requirements.txt Usage In order to run the project, execute the main.py in the root directory of the project: poetry run main.py To change which image / video to process, simply change the path in the main.py file Info The results for each image & video can be found in the data/output directory. Applied Techniques In the following section it will be explained, which techniques are subsequently applied to the images and videos in order to detect lane markings. Camera Calibration For the Udacity images & videos it is required to undistort the images. This is done by using the cv2.calibrateCamera() function. The calibration is achieved by using the provided chessboard images. The chessboard images are used to calculate the camera matrix and distortion coefficients. The camera matrix and distortion coefficients are then used to undistort the images. Image Segmentation Once the image has been undisorted, the next step is to segment the image. This is done by using the cv2.getPerspectiveTransform() function. The function takes the region of interest & destination format points as parameters. The region of interest points are the points of the original image, which should be transformed. The format of the region of interest varies between Udacity images & KITTI images. Below is an example for a KITTI image: Color Channel Thresholding In order to highlight line markings and remove unwanted colors. Thresholds are applied to different channels. The following channels are used: R : The red channel of the originial \"BGR\" color space is used since some line markings are yellow, therefore having a relatively high red value. The green channel was not used since green colors are more likely to be present on the side of the road, adding unwanted noise. L of the HSL space: As lane markings usually have a higher lightness value, compared to the darker asphalt, this channel is used to improve visibility of white lines. S of the HSL space: Additionally, Since not all lane markings are white, the saturation channel is used to highlight yellow lines as they often have a higher saturation value than darker asphalt. Canny : Some pictures do not contain line markings, therefore the Canny edge algorithm is used on the original transformed image to detect edges. Info Canny edge detection was added to allow lane detection on all KITTI images, especially the last one. Once the thresholds have been applied to each channel, the results are combined as follow: # If edge detection is not used cv2 . bitwise_or ( cv2 . bitwise_and ( R , S ), L ) # If edge detection is used cv2 . bitwise_or ( cv2 . bitwise_or ( cv2 . bitwise_and ( R , S ), L ), Canny ) Info However, due to some light changes in the challenge_video it was difficult to find certain thresholds fitting the entire image. Therefore, before applying thresholding, the image is seperated into multiple stripes. Then different thresholds are used depending on the mean lightness value of each strip. Once this is done, the results are concetaned, as can be seen in the image below: Perspective Transformation After the region of interest has been determined and thresholds have been applied to the image, the transformation matrix and inverse transformation matrix are calculated. The transformation matrix is then used with the cv2.warpPerspective method to transform the image to a bird's eye view. An example is given below: Polynomial Fitting After transforming the region of interest, the best second degree polynomial can be determined. To achieve this, the sliding window technique is applied to the transformed image to calculate a polynomial for the left and right line. After that, the polynomial is adjusted based on its proximity to fit the line markings better. Lastly, if the mean squared error between the newly calculated polynomial and the polynomial used for the last frame pass a certain threshold, the new calculated fit is discarded, because this is an indicator for a misfitted polynomial. Info Initially, the attempt was to use the integral beween the two polynomials to determine an error threshold, however the mean squared error was found to be more reliable. Sliding Windows This technique divides the image into multiple small regions of interest (windows), which have a fixed width, height and y-location, but can move along the x-axis. In our project, we use ten windows, which means that each window has the height of 1/10th of the images' height, with every y-coordinate having exactly one corresponding window. The first step of this technique is to calculate a histogram which holds the amount of white pixel per x-coordinate. Next, the peak of this histogram is used as the starting x-coordinate for the lowest window. Next, the average x location of all white pixels within this window is calculated. This average is the x-location of the window above. This process is repeated until all x-locations for all windows are determined. Next, the polynomial fit is calculated based on all white pixels which are in any window. Proximity Fitting Once the polynomial for the sliding windows has been calculated, a second polynomial is fitted to the white pixels within a certain proximity to the first polynomial. In the example below the green line marks the first polynomial which was fitted using the sliding windows. The yellow borders demonstrate the close proximity of the first polynomial. The white pixels inside the yellow borders are used to calculate the second polynomial, which is displayed in red. Increasing performance The performance of polynomial fitting can be increased if it is applied to a video. If the polynomial from the last frame has enough white pixel in its proximity, the sliding window technique can be skipped and the polynomial is only adjusted based on its proximity. Additionally, since the proximity is narrower than the sliding windows, fitting the proximity polynomial is faster, as less white pixels have to be considered. Plotting After the polynomials for both lines are calculated, the result has to be plotted to the undistorted image. To achieve this, we first calculate the x-coordinate of every y-coordinate for both polynomials. Next, these points are transformed back using the inverse matrix from the transformation step. Lastly, the area between all points is filled with a green color to visualize the resulting detected lane. Lessons Learned Image processing is a versatile topic and can be applied to many different areas. We learned that it is quite difficult to develop one robust pipeline which works well for all images, rather than developing multiple approaches which work well for fixed / pre-defined scenarios. At one point making changes to certain parameters to improve line detection in one specific image, can have a negative impact on the detection of other images. Therefore its quite hard to find an optimal solution.","title":"Readme"},{"location":"#abstract","text":"This project was developed by a team of 3 students as part of the \"Digitale-Bildverarbeitung\" course at DHBW Stuttgart . The goal was to implement an image & video processing application in Python. The application should be able to process frames to detect lanes and highlight them in the original image.","title":"Abstract"},{"location":"#credit","text":"Credit has to be given to Addison Sears-Collins who has published an easy to understand guide for the sliding window technique used in this project.","title":"Credit"},{"location":"#project-requirements","text":"Camera calibration of Udacity Images & Videos Image segmentation & Bird's Eye View transformation Applying thresholds to different color spaces to highlight relevant lane markings Curve / Polynomial fitting and plotting on image Video processing > 20 FPS","title":"Project Requirements"},{"location":"#additional-tasks","text":"Relevent lane markings are highlighted on the challenge_video Relevant lane markings are highlighted on each KITTI image The region of interest had to be adapted to the KITTI camera perspective Edge detection is applied to KITTI to detect lanes withouth any markings Steps for increased performance Region is transormed to a smaller image, reducing its size by a factor of 4 If enough white pixels are in close proximity to the previous polynomial, the sliding window technique is not applied. Since the proximity is narrower than the sliding windows, fitting the polynomial is faster, increasing performance. Calculations, which can be reused are performed at the beginning of a video and reused for each frame. Such as transform_matrix and camera calibration .","title":"Additional Tasks"},{"location":"#requirements-installation","text":"Python 3.10 is required Using Poetry Install Poetry # Linux, macOS, and Windows (WSL) curl -sSL https://install.python-poetry.org | python3 - # Windows (PowerShell) ( Invoke-WebRequest -Uri https://install.python-poetry.org -UseBasicParsing ) .Content | py - Install dependencies poetry install Running commands poetry run <command> Using pip pip install -r requirements.txt","title":"Requirements &amp; Installation"},{"location":"#usage","text":"In order to run the project, execute the main.py in the root directory of the project: poetry run main.py To change which image / video to process, simply change the path in the main.py file Info The results for each image & video can be found in the data/output directory.","title":"Usage"},{"location":"#applied-techniques","text":"In the following section it will be explained, which techniques are subsequently applied to the images and videos in order to detect lane markings.","title":"Applied Techniques"},{"location":"#camera-calibration","text":"For the Udacity images & videos it is required to undistort the images. This is done by using the cv2.calibrateCamera() function. The calibration is achieved by using the provided chessboard images. The chessboard images are used to calculate the camera matrix and distortion coefficients. The camera matrix and distortion coefficients are then used to undistort the images.","title":"Camera Calibration"},{"location":"#image-segmentation","text":"Once the image has been undisorted, the next step is to segment the image. This is done by using the cv2.getPerspectiveTransform() function. The function takes the region of interest & destination format points as parameters. The region of interest points are the points of the original image, which should be transformed. The format of the region of interest varies between Udacity images & KITTI images. Below is an example for a KITTI image:","title":"Image Segmentation"},{"location":"#color-channel-thresholding","text":"In order to highlight line markings and remove unwanted colors. Thresholds are applied to different channels. The following channels are used: R : The red channel of the originial \"BGR\" color space is used since some line markings are yellow, therefore having a relatively high red value. The green channel was not used since green colors are more likely to be present on the side of the road, adding unwanted noise. L of the HSL space: As lane markings usually have a higher lightness value, compared to the darker asphalt, this channel is used to improve visibility of white lines. S of the HSL space: Additionally, Since not all lane markings are white, the saturation channel is used to highlight yellow lines as they often have a higher saturation value than darker asphalt. Canny : Some pictures do not contain line markings, therefore the Canny edge algorithm is used on the original transformed image to detect edges. Info Canny edge detection was added to allow lane detection on all KITTI images, especially the last one. Once the thresholds have been applied to each channel, the results are combined as follow: # If edge detection is not used cv2 . bitwise_or ( cv2 . bitwise_and ( R , S ), L ) # If edge detection is used cv2 . bitwise_or ( cv2 . bitwise_or ( cv2 . bitwise_and ( R , S ), L ), Canny ) Info However, due to some light changes in the challenge_video it was difficult to find certain thresholds fitting the entire image. Therefore, before applying thresholding, the image is seperated into multiple stripes. Then different thresholds are used depending on the mean lightness value of each strip. Once this is done, the results are concetaned, as can be seen in the image below:","title":"Color Channel Thresholding"},{"location":"#perspective-transformation","text":"After the region of interest has been determined and thresholds have been applied to the image, the transformation matrix and inverse transformation matrix are calculated. The transformation matrix is then used with the cv2.warpPerspective method to transform the image to a bird's eye view. An example is given below:","title":"Perspective Transformation"},{"location":"#polynomial-fitting","text":"After transforming the region of interest, the best second degree polynomial can be determined. To achieve this, the sliding window technique is applied to the transformed image to calculate a polynomial for the left and right line. After that, the polynomial is adjusted based on its proximity to fit the line markings better. Lastly, if the mean squared error between the newly calculated polynomial and the polynomial used for the last frame pass a certain threshold, the new calculated fit is discarded, because this is an indicator for a misfitted polynomial. Info Initially, the attempt was to use the integral beween the two polynomials to determine an error threshold, however the mean squared error was found to be more reliable.","title":"Polynomial Fitting"},{"location":"#sliding-windows","text":"This technique divides the image into multiple small regions of interest (windows), which have a fixed width, height and y-location, but can move along the x-axis. In our project, we use ten windows, which means that each window has the height of 1/10th of the images' height, with every y-coordinate having exactly one corresponding window. The first step of this technique is to calculate a histogram which holds the amount of white pixel per x-coordinate. Next, the peak of this histogram is used as the starting x-coordinate for the lowest window. Next, the average x location of all white pixels within this window is calculated. This average is the x-location of the window above. This process is repeated until all x-locations for all windows are determined. Next, the polynomial fit is calculated based on all white pixels which are in any window.","title":"Sliding Windows"},{"location":"#proximity-fitting","text":"Once the polynomial for the sliding windows has been calculated, a second polynomial is fitted to the white pixels within a certain proximity to the first polynomial. In the example below the green line marks the first polynomial which was fitted using the sliding windows. The yellow borders demonstrate the close proximity of the first polynomial. The white pixels inside the yellow borders are used to calculate the second polynomial, which is displayed in red.","title":"Proximity Fitting"},{"location":"#increasing-performance","text":"The performance of polynomial fitting can be increased if it is applied to a video. If the polynomial from the last frame has enough white pixel in its proximity, the sliding window technique can be skipped and the polynomial is only adjusted based on its proximity. Additionally, since the proximity is narrower than the sliding windows, fitting the proximity polynomial is faster, as less white pixels have to be considered.","title":"Increasing performance"},{"location":"#plotting","text":"After the polynomials for both lines are calculated, the result has to be plotted to the undistorted image. To achieve this, we first calculate the x-coordinate of every y-coordinate for both polynomials. Next, these points are transformed back using the inverse matrix from the transformation step. Lastly, the area between all points is filled with a green color to visualize the resulting detected lane.","title":"Plotting"},{"location":"#lessons-learned","text":"Image processing is a versatile topic and can be applied to many different areas. We learned that it is quite difficult to develop one robust pipeline which works well for all images, rather than developing multiple approaches which work well for fixed / pre-defined scenarios. At one point making changes to certain parameters to improve line detection in one specific image, can have a negative impact on the detection of other images. Therefore its quite hard to find an optimal solution.","title":"Lessons Learned"},{"location":"calibration/","text":"get_camera_calibration ( plot = False ) Gets camera calibration based on Udacity sample pictures. Parameters: Name Type Description Default plot bool , optional Whether or not calibration images should be plotted, by default False False Returns: Type Description Parameters required to undistored image.","title":"Calibration"},{"location":"calibration/#src.calibration.get_camera_calibration","text":"Gets camera calibration based on Udacity sample pictures. Parameters: Name Type Description Default plot bool , optional Whether or not calibration images should be plotted, by default False False Returns: Type Description Parameters required to undistored image.","title":"get_camera_calibration()"},{"location":"detection/","text":"calculate_mean_squared_error ( last_fit , new_fit , height ) Calculates the mean squared error of the new_fit polynomial compared to given last_fit polynomial. Parameters: Name Type Description Default last_fit NDArray [ np . float64 ] Polynomial of 2 degrees required new_fit NDArray [ np . float64 ] Polynomial of 2 degrees required height int Max y value the error should be calculated of required Returns: Type Description float Mean Squared error get_fit ( param_image , last_left_fit = None , last_right_fit = None , last_left_fit_indices = None , last_right_fit_indices = None , plot = False ) Return fit for highlighted image First check if enough white pixel are inside the proximity of the last polynomial. If not enough pixels are inside the proximity or no last polynomial is provided, a new polynomial is calculated using sliding windows. After that, the polynomial is reshaped based on its proximity to better fit it. Lastly, if the polynomial changed too much, the new polynomial is discarded and the old one is returned. If any step should fail because of too little white pixel, no polynomial is returned. This entire procedure is executed for both the left and right side to get two polynomials that form the street lane. Parameters: Name Type Description Default param_image NDArray [ np . uint8 ] highlighted and transformed image required last_left_fit NDArray [ np . float64 ] | None, optional left polynomial of last frame, if it exists, by default None None last_right_fit NDArray [ np . float64 ] | None, optional right polynomial of last frame, if it exists, by default None None last_left_fit_indices NDArray [ np . float64 ] | None, optional the corresponding x value for the entire height, for the left polynomial, by default None None last_right_fit_indices NDArray [ np . float64 ] | None, optional the corresponding x value for the entire height, for the right polynomial, by default None None plot bool , optional if the result should be plotted, by default False False Returns: Type Description tuple [ NDArray [ np . float64 ] | None, NDArray [ np . float64 ] | None, NDArray [ np . float64 ] | None, NDArray [ np . float64 ] | None] new left fit, new left fit indices, new right fit, new right fit indices get_proximity_fit ( image_height , proximity_pixel_values_x , proximity_pixel_values_y ) Fits a new polynomial to the white pixels that are in close proximity of the last fitted polynomial. Parameters: Name Type Description Default image_height NDArray [ np . uint8 ] Height of image the polynomial should be fitted to required proximity_pixel_values_x NDArray [ np . intp ] x-values of white pixels that are in close proximity to the last polynomial required proximity_pixel_values_y NDArray [ np . intp ] y-values of white pixels that are in close proximity to the last polynomial required Returns: Type Description tuple [ NDArray [ np . float64 ], NDArray [ np . float64 ]] | None New fitted polynomial and all x-values of the polynomial for every y-value of the image get_window_fit ( histogram , historgram_min_x , histogram_max_x , image , white_pixel_indices_x , white_pixel_indices_y , window_amount ) Fits a polynomial for the provided x range with the sliding window technique Parameters: Name Type Description Default histogram NDArray [ np . uint32 ] histogram for white pixels for the entire length of the image required historgram_min_x int lower x boundary for histogram area that should be considered required histogram_max_x int upper x boundary for histogram area that should be considered required image NDArray [ np . uint8 ] the image which is analysed required white_pixel_indices_x NDArray [ np . intp ] list of x values of all white pixels required white_pixel_indices_y NDArray [ np . intp ] list of y values of all white pixels required window_amount int number of windows used for sliding windows technique required Returns: Type Description NDArray [ np . float64 ] | None polynomial of the calculated fit histogram_peak ( histogram , min_x , max_x ) Returns peak of provided histogram Parameters: Name Type Description Default histogram NDArray [ np . uint32 ] histogram that should be searched required min_x int lower boundary of search area required max_x int upper boundary of search area required Returns: Type Description int x position of histogram peak","title":"Detection"},{"location":"detection/#src.detection.calculate_mean_squared_error","text":"Calculates the mean squared error of the new_fit polynomial compared to given last_fit polynomial. Parameters: Name Type Description Default last_fit NDArray [ np . float64 ] Polynomial of 2 degrees required new_fit NDArray [ np . float64 ] Polynomial of 2 degrees required height int Max y value the error should be calculated of required Returns: Type Description float Mean Squared error","title":"calculate_mean_squared_error()"},{"location":"detection/#src.detection.get_fit","text":"Return fit for highlighted image First check if enough white pixel are inside the proximity of the last polynomial. If not enough pixels are inside the proximity or no last polynomial is provided, a new polynomial is calculated using sliding windows. After that, the polynomial is reshaped based on its proximity to better fit it. Lastly, if the polynomial changed too much, the new polynomial is discarded and the old one is returned. If any step should fail because of too little white pixel, no polynomial is returned. This entire procedure is executed for both the left and right side to get two polynomials that form the street lane. Parameters: Name Type Description Default param_image NDArray [ np . uint8 ] highlighted and transformed image required last_left_fit NDArray [ np . float64 ] | None, optional left polynomial of last frame, if it exists, by default None None last_right_fit NDArray [ np . float64 ] | None, optional right polynomial of last frame, if it exists, by default None None last_left_fit_indices NDArray [ np . float64 ] | None, optional the corresponding x value for the entire height, for the left polynomial, by default None None last_right_fit_indices NDArray [ np . float64 ] | None, optional the corresponding x value for the entire height, for the right polynomial, by default None None plot bool , optional if the result should be plotted, by default False False Returns: Type Description tuple [ NDArray [ np . float64 ] | None, NDArray [ np . float64 ] | None, NDArray [ np . float64 ] | None, NDArray [ np . float64 ] | None] new left fit, new left fit indices, new right fit, new right fit indices","title":"get_fit()"},{"location":"detection/#src.detection.get_proximity_fit","text":"Fits a new polynomial to the white pixels that are in close proximity of the last fitted polynomial. Parameters: Name Type Description Default image_height NDArray [ np . uint8 ] Height of image the polynomial should be fitted to required proximity_pixel_values_x NDArray [ np . intp ] x-values of white pixels that are in close proximity to the last polynomial required proximity_pixel_values_y NDArray [ np . intp ] y-values of white pixels that are in close proximity to the last polynomial required Returns: Type Description tuple [ NDArray [ np . float64 ], NDArray [ np . float64 ]] | None New fitted polynomial and all x-values of the polynomial for every y-value of the image","title":"get_proximity_fit()"},{"location":"detection/#src.detection.get_window_fit","text":"Fits a polynomial for the provided x range with the sliding window technique Parameters: Name Type Description Default histogram NDArray [ np . uint32 ] histogram for white pixels for the entire length of the image required historgram_min_x int lower x boundary for histogram area that should be considered required histogram_max_x int upper x boundary for histogram area that should be considered required image NDArray [ np . uint8 ] the image which is analysed required white_pixel_indices_x NDArray [ np . intp ] list of x values of all white pixels required white_pixel_indices_y NDArray [ np . intp ] list of y values of all white pixels required window_amount int number of windows used for sliding windows technique required Returns: Type Description NDArray [ np . float64 ] | None polynomial of the calculated fit","title":"get_window_fit()"},{"location":"detection/#src.detection.histogram_peak","text":"Returns peak of provided histogram Parameters: Name Type Description Default histogram NDArray [ np . uint32 ] histogram that should be searched required min_x int lower boundary of search area required max_x int upper boundary of search area required Returns: Type Description int x position of histogram peak","title":"histogram_peak()"},{"location":"image/","text":"display_image ( path , output_path = None ) Displays image stored under given path. Function performs pre-processing, segmentation, and lane detection. Parameters: Name Type Description Default path str Path image is stored under that should be plotted. required output_path str | None Path output image should be stored at, dy default None None","title":"Image"},{"location":"image/#src.image.display_image","text":"Displays image stored under given path. Function performs pre-processing, segmentation, and lane detection. Parameters: Name Type Description Default path str Path image is stored under that should be plotted. required output_path str | None Path output image should be stored at, dy default None None","title":"display_image()"},{"location":"license/","text":"MIT License Copyright (c) 2022 Nick Schroeder, Stephan auf der Landwehr, and Fabian Thome Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"pre_processing/","text":"calculate_histogram ( image ) Calculate histogram containing the amount of white pixels per x value Parameters: Name Type Description Default image NDArray [ np . uint8 ] the image the histogram should be calculated for required Returns: Type Description NDArray [ np . uint32 ] the resulting histogram get_transformation_matrices ( roi , destination_format ) Calculates transformation matrix and the respective inverse matrix based on given region of interest trapeze and given destination format. Parameters: Name Type Description Default roi NDArray [ np . float32 ] Region of interest / part of the original image that should be transformed into bird's view. required destination_format NDArray [ np . float32 ] Desired format of transformed image required Returns: Type Description tuple [ NDArray [ np . float64 ], NDArray [ np . float64 ]] Returns transformation matrix and inverse matrix highlight_lines ( image , gaussian_ksize = 3 , apply_edge_detection = True , plot = False ) Isolate lane indicators from image Parameters: Name Type Description Default image NDArray [ np . uint8 ] the image on which the lane lines should be isolated required gaussian_ksize int , optional size of gaussian filter, by default 3 3 apply_edge_detection bool , optional whether or not edge detection should be applied, by default True True plot bool , optional whether or not the result should be plotted, by default False False Returns: Type Description NDArray [ np . uint8 ] image with the lane lines being highlighted perspective_transform ( image , transformation_matrix , destination_format , plot = False ) Performs the perspective transform on provided image with provided transformation which should be calculated using the get_transformation_matrices method. Parameters: Name Type Description Default image NDArray [ np . uint8 ] Image that should be transformed into bird's view required transformation_matrix NDArray [ np . float64 ] Matrix used for transformation required destination_format NDArray [ np . int32 ] Desired result format after image was transformed required plot bool , optional Whether or not transformed image should be plotted, by default False False Returns: Type Description NDArray [ np . uint8 ] Transformed image","title":"Pre-Processing"},{"location":"pre_processing/#src.pre_processing.calculate_histogram","text":"Calculate histogram containing the amount of white pixels per x value Parameters: Name Type Description Default image NDArray [ np . uint8 ] the image the histogram should be calculated for required Returns: Type Description NDArray [ np . uint32 ] the resulting histogram","title":"calculate_histogram()"},{"location":"pre_processing/#src.pre_processing.get_transformation_matrices","text":"Calculates transformation matrix and the respective inverse matrix based on given region of interest trapeze and given destination format. Parameters: Name Type Description Default roi NDArray [ np . float32 ] Region of interest / part of the original image that should be transformed into bird's view. required destination_format NDArray [ np . float32 ] Desired format of transformed image required Returns: Type Description tuple [ NDArray [ np . float64 ], NDArray [ np . float64 ]] Returns transformation matrix and inverse matrix","title":"get_transformation_matrices()"},{"location":"pre_processing/#src.pre_processing.highlight_lines","text":"Isolate lane indicators from image Parameters: Name Type Description Default image NDArray [ np . uint8 ] the image on which the lane lines should be isolated required gaussian_ksize int , optional size of gaussian filter, by default 3 3 apply_edge_detection bool , optional whether or not edge detection should be applied, by default True True plot bool , optional whether or not the result should be plotted, by default False False Returns: Type Description NDArray [ np . uint8 ] image with the lane lines being highlighted","title":"highlight_lines()"},{"location":"pre_processing/#src.pre_processing.perspective_transform","text":"Performs the perspective transform on provided image with provided transformation which should be calculated using the get_transformation_matrices method. Parameters: Name Type Description Default image NDArray [ np . uint8 ] Image that should be transformed into bird's view required transformation_matrix NDArray [ np . float64 ] Matrix used for transformation required destination_format NDArray [ np . int32 ] Desired result format after image was transformed required plot bool , optional Whether or not transformed image should be plotted, by default False False Returns: Type Description NDArray [ np . uint8 ] Transformed image","title":"perspective_transform()"},{"location":"segmentation/","text":"draw_roi ( image , roi_trapeze , plot = False ) Visualises region of interest on the image Parameters: Name Type Description Default image NDArray [ np . uint8 ] image the roi should be plottet on required roi_trapeze NDArray [ np . int32 ] points of region of interest required plot bool , optional whether or not the image should be plotted, by default False False Returns: Type Description NDArray [ np . uint8 ] image with the region of interest polttet to it get_roi ( height , width , is_udacity = True ) Return Region of interest for the provided image scale Parameters: Name Type Description Default height int height of the image required width int width of the image required is_udacity bool , optional whether or not the image is a udacity image, by default True True Returns: Type Description NDArray [ np . float32 ] trapeze of the region of interest overlay_lane_lines ( original_image , transformed_image , left_fit_x_indices , right_fit_x_indices , inverse_transformation_matrix , plot = False ) Draw detected lines to provided image Parameters: Name Type Description Default original_image NDArray [ np . uint8 ] the image the lanes should be plotted to required transformed_image NDArray [ np . uint8 ] the transformed image the lanes are calculated for required left_fit_x_indices NDArray [ np . float64 ] the corresponding x value for the entire height, for the left polynomial required right_fit_x_indices NDArray [ np . float64 ] the corresponding x value for the entire height, for the right polynomial required inverse_transformation_matrix NDArray [ np . float64 ] inverse matrix for transformed image required plot bool , optional whether or not the result should be plotted, by default False False Returns: Type Description NDArray [ np . uint8 ] the original image with the lane painted to it","title":"Segmentation"},{"location":"segmentation/#src.segmentation.draw_roi","text":"Visualises region of interest on the image Parameters: Name Type Description Default image NDArray [ np . uint8 ] image the roi should be plottet on required roi_trapeze NDArray [ np . int32 ] points of region of interest required plot bool , optional whether or not the image should be plotted, by default False False Returns: Type Description NDArray [ np . uint8 ] image with the region of interest polttet to it","title":"draw_roi()"},{"location":"segmentation/#src.segmentation.get_roi","text":"Return Region of interest for the provided image scale Parameters: Name Type Description Default height int height of the image required width int width of the image required is_udacity bool , optional whether or not the image is a udacity image, by default True True Returns: Type Description NDArray [ np . float32 ] trapeze of the region of interest","title":"get_roi()"},{"location":"segmentation/#src.segmentation.overlay_lane_lines","text":"Draw detected lines to provided image Parameters: Name Type Description Default original_image NDArray [ np . uint8 ] the image the lanes should be plotted to required transformed_image NDArray [ np . uint8 ] the transformed image the lanes are calculated for required left_fit_x_indices NDArray [ np . float64 ] the corresponding x value for the entire height, for the left polynomial required right_fit_x_indices NDArray [ np . float64 ] the corresponding x value for the entire height, for the right polynomial required inverse_transformation_matrix NDArray [ np . float64 ] inverse matrix for transformed image required plot bool , optional whether or not the result should be plotted, by default False False Returns: Type Description NDArray [ np . uint8 ] the original image with the lane painted to it","title":"overlay_lane_lines()"},{"location":"video/","text":"concatenate_images ( highlighted_image_with_polynomials , transformed_image , output_image ) Concatenates highlighted, transformed, and image with undisorted image with polynomials to one image. Parameters: Name Type Description Default highlighted_image_with_polynomials NDArray [ np . uint8 ] highlighted as color image with polynomials plotted required transformed_image NDArray [ np . uint8 ] transformed image in bird's eye view required output_image NDArray [ np . uint8 ] undisorted image with polynomials plotted required Returns: Type Description NDArray [ np . uint8 ] returns concatenated image with highlighted in the top left corner , transformed in top right corner, and the undisorted image with polynomials on the bottom display_video ( path , output_path = None ) Displays video stored under given path. Function performs pre-processing, segmentation, and lane detection. Parameters: Name Type Description Default path str Path video is stored under that should be plotted. required output_path str | None Path the output should be saved to, by default None None","title":"Video"},{"location":"video/#src.video.concatenate_images","text":"Concatenates highlighted, transformed, and image with undisorted image with polynomials to one image. Parameters: Name Type Description Default highlighted_image_with_polynomials NDArray [ np . uint8 ] highlighted as color image with polynomials plotted required transformed_image NDArray [ np . uint8 ] transformed image in bird's eye view required output_image NDArray [ np . uint8 ] undisorted image with polynomials plotted required Returns: Type Description NDArray [ np . uint8 ] returns concatenated image with highlighted in the top left corner , transformed in top right corner, and the undisorted image with polynomials on the bottom","title":"concatenate_images()"},{"location":"video/#src.video.display_video","text":"Displays video stored under given path. Function performs pre-processing, segmentation, and lane detection. Parameters: Name Type Description Default path str Path video is stored under that should be plotted. required output_path str | None Path the output should be saved to, by default None None","title":"display_video()"}]}